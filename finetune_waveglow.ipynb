{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune_waveglow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGiNTMShZYvj",
        "colab": {}
      },
      "source": [
        "# download LJSpeech dataset\n",
        "!wget http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "# decompress\n",
        "!tar -xvjf LJSpeech-1.1.tar.bz2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWkMdnzB_RuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell imports the drive library and mounts your Google Drive as a VM local drive.  \n",
        "# You can access to your Drive files using this path \"/content/gdrive/My Drive/\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7leR6e15ZSg",
        "colab_type": "code",
        "outputId": "d1b1b11d-e3e7-435f-ea4a-526ce9218d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "!pip install ffmpeg\n",
        "!pip install torchaudio"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-cp36-none-any.whl size=6085 sha256=43814fcb29e2dbae06971acb5485645875876d30469b7614b521fd4362a69709\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/3d/7bcc3476f00d8dd8735d384230cb787d7e91ce6e1b51cef802d6bc5f4ff3/torchaudio-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 2.7MB/s \n",
            "\u001b[?25hCollecting torch==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.0->torchaudio) (1.17.3)\n",
            "\u001b[31mERROR: torchvision 0.4.2+cu100 has requirement torch==1.3.1, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchaudio\n",
            "  Found existing installation: torch 1.3.1+cu100\n",
            "    Uninstalling torch-1.3.1+cu100:\n",
            "      Successfully uninstalled torch-1.3.1+cu100\n",
            "Successfully installed torch-1.3.0 torchaudio-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8i76i7MXBkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "aabf6c90-5134-415c-c113-b674093812c0"
      },
      "source": [
        "# lädt mp3 file und konvertiert es zu wav\n",
        "!ffmpeg -i \"/content/gdrive/My Drive/text2speech/DieRachederSithStarWarsEpisode3_ep7_Full length.mp3\" -acodec pcm_s16le -ar 22050 sample.wav"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;35m[wav @ 0x55717c37cc00] \u001b[0m\u001b[1;31mFilesize 4437127656 invalid for wav, output file will be broken\n",
            "\u001b[0msize= 4333132kB time=13:58:27.56 bitrate= 705.6kbits/s speed= 425x    \n",
            "video:0kB audio:4333132kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000011%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_yZHn6G5cxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/audio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIzeaGi5mXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "734eb2ee-c072-4556-98b4-f57f35b9932f"
      },
      "source": [
        "cd /content/audio\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/audio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfYOp9WK5dLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# erzeugt mp3 Schnipsel mit 8 sec Dauer\n",
        "!ffmpeg -i \"/content/sample.wav\" -f segment -segment_time 8 -c copy out%03d.wav\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BRMurq05d46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6276cf47-2486-4da3-cd1c-6c1913e09dab"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0-ajUc2eJQ",
        "colab_type": "code",
        "outputId": "0705cdf5-ecea-49e4-8f55-903fe5a14dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!git clone https://github.com/NVIDIA/waveglow.git\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'waveglow'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "Receiving objects:   0% (1/176)   \rReceiving objects:   1% (2/176)   \rReceiving objects:   2% (4/176)   \rReceiving objects:   3% (6/176)   \rReceiving objects:   4% (8/176)   \rReceiving objects:   5% (9/176)   \rReceiving objects:   6% (11/176)   \rReceiving objects:   7% (13/176)   \rReceiving objects:   8% (15/176)   \rReceiving objects:   9% (16/176)   \rReceiving objects:  10% (18/176)   \rReceiving objects:  11% (20/176)   \rReceiving objects:  12% (22/176)   \rReceiving objects:  13% (23/176)   \rReceiving objects:  14% (25/176)   \rReceiving objects:  15% (27/176)   \rReceiving objects:  16% (29/176)   \rReceiving objects:  17% (30/176)   \rReceiving objects:  18% (32/176)   \rReceiving objects:  19% (34/176)   \rReceiving objects:  20% (36/176)   \rReceiving objects:  21% (37/176)   \rReceiving objects:  22% (39/176)   \rReceiving objects:  23% (41/176)   \rReceiving objects:  24% (43/176)   \rReceiving objects:  25% (44/176)   \rReceiving objects:  26% (46/176)   \rReceiving objects:  27% (48/176)   \rReceiving objects:  28% (50/176)   \rReceiving objects:  29% (52/176)   \rReceiving objects:  30% (53/176)   \rReceiving objects:  31% (55/176)   \rReceiving objects:  32% (57/176)   \rReceiving objects:  33% (59/176)   \rReceiving objects:  34% (60/176)   \rReceiving objects:  35% (62/176)   \rReceiving objects:  36% (64/176)   \rReceiving objects:  37% (66/176)   \rReceiving objects:  38% (67/176)   \rReceiving objects:  39% (69/176)   \rReceiving objects:  40% (71/176)   \rReceiving objects:  41% (73/176)   \rReceiving objects:  42% (74/176)   \rReceiving objects:  43% (76/176)   \rReceiving objects:  44% (78/176)   \rReceiving objects:  45% (80/176)   \rReceiving objects:  46% (81/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  47% (83/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  48% (85/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  49% (87/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  50% (88/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  51% (90/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  52% (92/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  53% (94/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  54% (96/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  55% (97/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  56% (99/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  57% (101/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  58% (103/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  59% (104/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  60% (106/176), 180.01 KiB | 330.00 KiB/s   \rremote: Total 176 (delta 0), reused 1 (delta 0), pack-reused 173\u001b[K\n",
            "Receiving objects:  61% (108/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  62% (110/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  63% (111/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  64% (113/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  65% (115/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  66% (117/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  67% (118/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  68% (120/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  69% (122/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  70% (124/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  71% (125/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  72% (127/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  73% (129/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  74% (131/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  75% (132/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  76% (134/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  77% (136/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  78% (138/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  79% (140/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  80% (141/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  81% (143/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  82% (145/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  83% (147/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  84% (148/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  85% (150/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  86% (152/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  87% (154/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  88% (155/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  89% (157/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  90% (159/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  91% (161/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  92% (162/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  93% (164/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  94% (166/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  95% (168/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  96% (169/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  97% (171/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  98% (173/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects:  99% (175/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects: 100% (176/176), 180.01 KiB | 330.00 KiB/s   \rReceiving objects: 100% (176/176), 434.05 KiB | 600.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/96)   \rResolving deltas:  16% (16/96)   \rResolving deltas:  23% (23/96)   \rResolving deltas:  27% (26/96)   \rResolving deltas:  31% (30/96)   \rResolving deltas:  37% (36/96)   \rResolving deltas:  44% (43/96)   \rResolving deltas:  53% (51/96)   \rResolving deltas:  75% (72/96)   \rResolving deltas:  90% (87/96)   \rResolving deltas: 100% (96/96)   \rResolving deltas: 100% (96/96), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz32ATCTbyrW",
        "colab_type": "code",
        "outputId": "a1301c69-3437-42ba-8b5f-1ac9a3342c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd waveglow"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/waveglow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkCaXTSbr16",
        "colab_type": "code",
        "outputId": "058ff4b7-f2fb-4a12-ec5f-ddb70050f3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submodule 'tacotron2' (http://github.com/NVIDIA/tacotron2) registered for path 'tacotron2'\n",
            "Cloning into '/content/waveglow/tacotron2'...\n",
            "warning: redirecting to https://github.com/NVIDIA/tacotron2/\n",
            "Submodule path 'tacotron2': checked out 'fc0cf6a89a47166350b65daa1beaa06979e4cddf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNtDq_dpBQZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -r /content/waveglow/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SgxegrrC1B0",
        "colab_type": "code",
        "outputId": "96c4791f-a765-46f8-cb11-d8df403ea78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "cd apex\n",
        "pip install -v --no-cache-dir ./\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UxL_4iTEdKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggsjPU5pG07Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVOcWKx7Zweq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e44a57b-ef1d-4361-e404-a5028332b51e"
      },
      "source": [
        "%%writefile  /content/waveglow/config.json\n",
        "\n",
        "{\n",
        "    \"train_config\": {\n",
        "        \"output_directory\": \"checkpoints\",\n",
        "        \"epochs\": 100000,\n",
        "        \"learning_rate\": 3e-5,\n",
        "        \"sigma\": 1.0,\n",
        "        \"iters_per_checkpoint\": 200,\n",
        "        \"batch_size\": 3,\n",
        "        \"seed\": 1234,\n",
        "        \"checkpoint_path\": \"/content/gdrive/My Drive/text2speech/ceckpoint_out.pth\"\n",
        "    },\n",
        "    \"data_config\": {\n",
        "        \"training_files\":\"/content/audio\",\n",
        "        \"segment_length\": 16000,\n",
        "        \"sampling_rate\": 22050,\n",
        "        \"filter_length\": 1024,\n",
        "        \"hop_length\": 256,\n",
        "        \"win_length\": 1024,\n",
        "        \"mel_fmin\": 0.0,\n",
        "        \"mel_fmax\": 8000.0\n",
        "    },\n",
        "    \"dist_config\": {\n",
        "        \"dist_backend\": \"nccl\",\n",
        "        \"dist_url\": \"tcp://localhost:54321\"\n",
        "    },\n",
        "\n",
        "    \"waveglow_config\": {\n",
        "        \"n_mel_channels\": 80,\n",
        "        \"n_flows\": 12,\n",
        "        \"n_group\": 8,\n",
        "        \"n_early_every\": 4,\n",
        "        \"n_early_size\": 2,\n",
        "        \"WN_config\": {\n",
        "            \"n_layers\": 8,\n",
        "            \"n_channels\": 512,\n",
        "            \"kernel_size\": 3\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/waveglow/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7nM3wdwaxpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65517f91-ae69-4f36-cd56-70f20ff507aa"
      },
      "source": [
        "cd /content/waveglow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/waveglow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNBhnNO245zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "from convert_model import update_model\n",
        "\n",
        "#=====START: ADDED FOR DISTRIBUTED======\n",
        "from distributed import init_distributed, apply_gradient_allreduce, reduce_tensor\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "#=====END:   ADDED FOR DISTRIBUTED======\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from glow import WaveGlow,WaveGlowLoss\n",
        "from mel2samp import Mel2Samp\n",
        "\n",
        "\n",
        "out_Path = '/content/gdrive/My Drive/text2speech/ceckpoint_out.pth'\n",
        "checkpoint_path = '/content/gdrive/My Drive/text2speech/ceckpoint_out.pth'\n",
        "load_check = 1\n",
        "from_scratch = 1 - load_check\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    assert os.path.isfile(checkpoint_path)\n",
        "    checkpoint_dict = torch.load(checkpoint_path, map_location='cpu')\n",
        "    iteration = checkpoint_dict['iteration']\n",
        "    optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
        "    model_for_loading = checkpoint_dict['model']\n",
        "    model.load_state_dict(model_for_loading.state_dict())\n",
        "    print(\"Loaded checkpoint '{}' (iteration {})\" .format(\n",
        "          checkpoint_path, iteration))\n",
        "    return model, optimizer, iteration\n",
        "\n",
        "def save_checkpoint(model, optimizer, learning_rate, iteration, filepath):\n",
        "    print(\"Saving model and optimizer state at iteration {} to {}\".format(\n",
        "          iteration, filepath))\n",
        "    #model_for_saving = WaveGlow(**waveglow_config).cuda()\n",
        "    #model_for_saving.load_state_dict(model.state_dict())\n",
        "    torch.save({'model': model,\n",
        "                'iteration': iteration,\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'learning_rate': learning_rate}, filepath)\n",
        "\n",
        "def train(num_gpus, rank, group_name, output_directory, epochs, learning_rate,\n",
        "          sigma, iters_per_checkpoint, batch_size, seed, checkpoint_path):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    #=====START: ADDED FOR DISTRIBUTED======\n",
        "    if num_gpus > 1:\n",
        "        init_distributed(rank, num_gpus, group_name, **dist_config)\n",
        "    #=====END:   ADDED FOR DISTRIBUTED======\n",
        "\n",
        "    criterion = WaveGlowLoss(sigma)\n",
        "    \n",
        "    \n",
        "    model = WaveGlow(**waveglow_config).cuda()\n",
        "    if from_scratch:\n",
        "        model = torch.load('/content/gdrive/My Drive/text2speech/waveglow_256channels.pt', map_location='cpu')['model']\n",
        "    #model = update_model(model)\n",
        "    model.cuda()\n",
        "   \n",
        "\n",
        "    #=====START: ADDED FOR DISTRIBUTED======\n",
        "    if num_gpus > 1:\n",
        "        model = apply_gradient_allreduce(model)\n",
        "    #=====END:   ADDED FOR DISTRIBUTED======\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Load checkpoint if one exists\n",
        "    iteration = 0\n",
        "    if load_check:\n",
        "        model, optimizer, iteration = load_checkpoint(checkpoint_path, model,\n",
        "                                                      optimizer)\n",
        "        iteration += 1  # next iteration is iteration + 1\n",
        "\n",
        "    trainset = Mel2Samp(**data_config)\n",
        "    # =====START: ADDED FOR DISTRIBUTED======\n",
        "    train_sampler = DistributedSampler(trainset) if num_gpus > 1 else None\n",
        "    # =====END:   ADDED FOR DISTRIBUTED======\n",
        "    train_loader = DataLoader(trainset, num_workers=1, shuffle=False,\n",
        "                              sampler=train_sampler,\n",
        "                              batch_size=batch_size,\n",
        "                              pin_memory=False,\n",
        "                              drop_last=True)\n",
        "\n",
        "    # Get shared output_directory ready\n",
        "    if rank == 0:\n",
        "        if not os.path.isdir(output_directory):\n",
        "            os.makedirs(output_directory)\n",
        "            os.chmod(output_directory, 0o775)\n",
        "        print(\"output directory\", output_directory)\n",
        "\n",
        "    model.train()\n",
        "    epoch_offset = max(0, int(iteration / len(train_loader)))\n",
        "    # ================ MAIN TRAINNIG LOOP! ===================\n",
        "    \n",
        "    steps = 3\n",
        "    for epoch in range(epoch_offset, epochs):\n",
        "        print(\"Epoch: {}\".format(epoch))\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            model.zero_grad()\n",
        "\n",
        "            mel, audio = batch\n",
        "            mel = torch.autograd.Variable(mel.cuda())\n",
        "            audio = torch.autograd.Variable(audio.cuda())\n",
        "            outputs = model((mel, audio))\n",
        "\n",
        "            loss = criterion(outputs)/steps\n",
        "            loss.backward()\n",
        "            \n",
        "            \n",
        "            if (i+1)%steps == 0:\n",
        "                print(\"{}:\\t{:.9f}\".format(iteration, loss))\n",
        "                \n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "               \n",
        "               \n",
        "                \n",
        "            ###\n",
        "            \n",
        "\n",
        "       \n",
        "            if (iteration % iters_per_checkpoint == 0):\n",
        "                if rank == 0:\n",
        "                    checkpoint_path = \"{}/waveglow_{}\".format(\n",
        "                        output_directory, iteration)\n",
        "                    save_checkpoint(model, optimizer, learning_rate, iteration,out_Path)\n",
        "\n",
        "            iteration += 1\n",
        "            \n",
        "            \n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Parse configs.  Globals nicer in this case\n",
        "    with open('/content/waveglow/config.json') as f:\n",
        "        data = f.read()\n",
        "    config = json.loads(data)\n",
        "    train_config = config[\"train_config\"]\n",
        "    global data_config\n",
        "    data_config = config[\"data_config\"]\n",
        "    global dist_config\n",
        "    dist_config = config[\"dist_config\"]\n",
        "    global waveglow_config\n",
        "    waveglow_config = config[\"waveglow_config\"]\n",
        "\n",
        "\n",
        "\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    model = train(1, 0,\"\", **train_config)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}